{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2dlClHLU0Oy",
        "outputId": "23c7a861-d50a-49e4-933e-bf76efff8286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Setosa       1.00      1.00      1.00        10\n",
            "  Versicolor       0.91      1.00      0.95        10\n",
            "   Virginica       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.00000000e+000, 3.97657460e-018, 1.81451748e-027],\n",
              "       [1.00000000e+000, 2.45767206e-017, 1.05156114e-026],\n",
              "       [1.00000000e+000, 3.89583737e-014, 3.68358197e-023],\n",
              "       [1.00000000e+000, 5.28897442e-016, 1.92033111e-025],\n",
              "       [1.00000000e+000, 1.51422161e-016, 1.84217680e-024],\n",
              "       [1.80457208e-290, 1.40779591e-012, 1.00000000e+000],\n",
              "       [1.40739455e-065, 9.99964106e-001, 3.58942386e-005],\n",
              "       [1.00000000e+000, 1.92996899e-017, 1.36149579e-026],\n",
              "       [2.19346281e-163, 2.46452157e-003, 9.97535478e-001],\n",
              "       [3.07550445e-088, 9.82019881e-001, 1.79801191e-002],\n",
              "       [2.66637859e-068, 9.99842060e-001, 1.57939971e-004],\n",
              "       [1.00000000e+000, 3.87137953e-018, 1.20990548e-027],\n",
              "       [2.23425927e-062, 9.99976684e-001, 2.33156717e-005],\n",
              "       [6.40135244e-066, 9.99975094e-001, 2.49063452e-005],\n",
              "       [4.62895800e-208, 1.53487073e-008, 9.99999985e-001],\n",
              "       [1.00000000e+000, 1.03584907e-017, 7.09356512e-027],\n",
              "       [1.12554698e-112, 9.32036282e-001, 6.79637184e-002],\n",
              "       [9.27068932e-238, 1.53856463e-010, 1.00000000e+000],\n",
              "       [3.57684736e-143, 1.76422258e-002, 9.82357774e-001],\n",
              "       [1.00000000e+000, 1.25375974e-018, 5.88160626e-028],\n",
              "       [4.51771634e-123, 2.24154501e-001, 7.75845499e-001],\n",
              "       [6.91432232e-181, 7.50047303e-006, 9.99992500e-001],\n",
              "       [8.69072872e-176, 1.00778064e-006, 9.99998992e-001],\n",
              "       [6.77944334e-106, 9.15387100e-001, 8.46129000e-002],\n",
              "       [1.00000000e+000, 3.13609128e-014, 1.21219738e-022],\n",
              "       [4.75042298e-248, 5.87335303e-012, 1.00000000e+000],\n",
              "       [4.81659352e-141, 5.36418307e-001, 4.63581693e-001],\n",
              "       [1.54487241e-058, 9.99991653e-001, 8.34735033e-006],\n",
              "       [2.66529334e-032, 9.99999874e-001, 1.25985300e-007],\n",
              "       [6.16122729e-105, 8.06904107e-001, 1.93095893e-001]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#import\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#iris = pd.read_csv(\"gnb_normalize_dataset_fix.csv\")\n",
        "iris = pd.read_csv(\"iris.csv\")\n",
        "#iris = pd.read_csv(\"dataset_enzim_3_pca.csv\")\n",
        "#iris = pd.read_csv(\"dataset_enzim_selected_feature.csv\")\n",
        "\n",
        "\n",
        "iris.head()\n",
        "\n",
        "#  variabel bebas\n",
        "x = iris.drop([\"variety\"], axis = 1)\n",
        "x.head()\n",
        "\n",
        "#variabel tidak bebas\n",
        "y = iris[\"variety\"]\n",
        "y.head()\n",
        "\n",
        "# classification \n",
        "# please install scikit library \n",
        "# pip install -U scikit-learn\n",
        "\n",
        "# separate the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 3)\n",
        "#import from library \n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "\n",
        "# Call Gaussian Naive Bayes \n",
        "iris_model = GaussianNB()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Insert the training dataset to  Naive Bayes function\n",
        "NB_train = iris_model.fit(x_train, y_train)\n",
        "\n",
        "# Next step: Prediction the x_test to the model built and save to the             y_pred variable \n",
        "# show the result of prediction \n",
        "y_pred = NB_train.predict(x_test)\n",
        "np.array(y_pred) \n",
        "\n",
        "# show the y_test based on separation dataset\n",
        "np.array(y_test)\n",
        "\n",
        "# show the confusion matrix based on the prediction result \n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test,y_pred)\n",
        "\n",
        "\n",
        "#evaluate performance from the confusion matrix \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "# this value will show all probability for each predicted class \n",
        "NB_train.predict_proba(x_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}